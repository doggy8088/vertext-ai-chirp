# ä½¿ç”¨ Google Chirp é€šç”¨èªéŸ³æ¨¡å‹é€²è¡Œé«˜å“è³ªèªéŸ³è­˜åˆ¥èˆ‡æ–‡å­—è½‰éŒ„

æœ€è¿‘ç ”ç©¶äº†å¤šå¥—èªéŸ³è½‰æ–‡å­—çš„æ¨¡å‹ï¼Œä»Šå¤©é€™ç¯‡æ–‡ç« æˆ‘æ‰“ç®—ä¾†åˆ†äº«ä¸€å¥—ç”± Google ç™¼å±•çš„ [Chirp](https://cloud.google.com/speech-to-text/v2/docs/chirp-model) é€šç”¨èªéŸ³æ¨¡å‹ ([Google USM](https://arxiv.org/pdf/2303.01037))ï¼Œè©²æ¨¡å‹èƒ½å¤ åœ¨å–®ä¸€æ¨¡å‹ä¸­çµ±ä¸€è™•ç†å¤šç¨®èªè¨€çš„æ•¸æ“šï¼Œç‚ºä½¿ç”¨è€…æä¾›æ›´ç²¾ç¢ºã€æ›´éˆæ´»çš„èªéŸ³è­˜åˆ¥é«”é©—ã€‚èˆ‡å‚³çµ±èªéŸ³æ¨¡å‹ä¸åŒï¼ŒChirp èƒ½å¤ è™•ç†æ›´å¤§å¡Šçš„èªéŸ³ç‰‡æ®µï¼Œé›–ç„¶é€™æ„å‘³è‘—å®ƒå¯èƒ½ä¸é©åˆçœŸæ­£çš„å³æ™‚æ‡‰ç”¨å ´æ™¯ï¼Œä½†åœ¨è™•ç†çŸ­éŸ³é »(å°æ–¼1åˆ†é˜)å’Œé•·éŸ³é »(1åˆ†é˜è‡³8å°æ™‚)æ™‚ï¼Œå…¶è¡¨ç¾å»ååˆ†å‡ºè‰²ã€‚

![An abstract digital illustration representing Google's Chirp speech model for high-quality speech recognition.](https://github.com/user-attachments/assets/9505a2c2-4b2c-4674-b81a-7f269e468f24)

[Chirp](https://cloud.google.com/speech-to-text/v2/docs/chirp-model) æ¨¡å‹çš„ä¸€å¤§äº®é»æ˜¯å…¶æ”¯æ´èªè¨€ç„¡é—œçš„éŸ³é »è½‰éŒ„åŠŸèƒ½ï¼Œèƒ½å¤ è‡ªå‹•æ¨æ–·éŸ³é »æ–‡ä»¶ä¸­çš„å£èªèªè¨€ä¸¦å°‡å…¶æ·»åŠ åˆ°çµæœä¸­ï¼Œé€™å°æ–¼è™•ç†å¤šèªè¨€ç’°å¢ƒä¸‹çš„èªéŸ³è­˜åˆ¥ä»»å‹™å…·æœ‰é‡è¦æ„ç¾©ã€‚æ­¤å¤–ï¼ŒChirp é‚„æ”¯æ´è‡ªå‹•æ¨™é»å’Œè©æ™‚é–“æˆ³ç­‰å¯¦ç”¨åŠŸèƒ½ï¼Œé€²ä¸€æ­¥æå‡äº†è½‰éŒ„çµæœçš„å¯è®€æ€§å’Œå¯¦ç”¨æ€§ã€‚

æ¥ä¸‹ä¾†æˆ‘æœƒå¸¶å¤§å®¶èµ°ä¸€é Chirp æ¨¡å‹çš„ä½¿ç”¨æ–¹å¼ï¼š

## 1. åˆå§‹åŒ– Google Cloud ç’°å¢ƒ

é–‹å§‹çš„æ­¥é©Ÿæ¯”è¼ƒéº»ç…©ï¼Œéœ€è¦å° Google Cloud ç’°å¢ƒæœ‰é»èªè­˜æ‰æœ‰è¾¦æ³•è¨­å®šå¥½ï¼š

1. ä½ è¦å…ˆå»ºç«‹ä¸€å€‹ [Google Cloud Console](https://console.cloud.google.com/) çš„å°ˆæ¡ˆ
2. å†åˆ° [å°ˆæ¡ˆé¸æ“‡å™¨](https://console.cloud.google.com/projectselector2/home/dashboard) é¸æ“‡ä¸€å€‹ç¾æœ‰çš„å°ˆæ¡ˆ
3. é‚„å¿…é ˆ[ç¢ºä¿ä½ çš„ Google Cloud å°ˆæ¡ˆå·²å•Ÿç”¨è¨ˆè²»](https://cloud.google.com/billing/docs/how-to/verify-billing-enabled#confirm_billing_is_enabled_on_a_project)
4. æœ€å¾Œé‚„è¦æ‰‹å‹•å•Ÿç”¨ [Cloud Speech-to-Text API API](https://console.cloud.google.com/flows/enableapi?apiid=speech.googleapis.com,) æ‰èƒ½é–‹å§‹ä½¿ç”¨ Chirp æœå‹™
5. å¦‚æœä½ ä¸æ˜¯ç®¡ç†è€…ï¼Œå¯èƒ½è¦è«‹äººå¹«ä½ æˆæ¬Š `Cloud Speech Administrator` è§’è‰²
6. å®‰è£ `gcloud` å‘½ä»¤åˆ—å·¥å…· ([Install the gcloud CLI](https://cloud.google.com/sdk/docs/install))
7. åˆå§‹åŒ– gcloud CLI åŸ·è¡Œç’°å¢ƒ

    ```sh
    gcloud init
    ```

8. ä»¥ç³»çµ±ç®¡ç†å“¡æ¬Šé™é–‹å•Ÿå¦é–‹ä¸€å€‹ Command Prompt è¦–çª—ä¸¦åŸ·è¡Œæ›´æ–°å‘½ä»¤

    ```sh
    gcloud components update
    ```

9. å»ºç«‹æœ¬åœ°èªè­‰æ†‘è­‰ (ADC)

    ```sh
    gcloud auth application-default login
    ```

    é€™å€‹å‘½ä»¤å¯ä»¥è®“ä½ å–å¾—**æ‡‰ç”¨ç¨‹å¼é è¨­æ†‘è­‰** ([Application Default Credentials](https://cloud.google.com/docs/authentication/application-default-credentials))ï¼Œç°¡ç¨± `ADC` çš„æ±è¥¿ï¼Œä»–å¯ä»¥è®“ä½ ä¹‹å¾Œçš„ç¨‹å¼éƒ½ä¸éœ€è¦ç‰¹åˆ¥è™•ç†é‡‘é‘°æˆ–èªè­‰ç­‰è¨­å®šï¼Œè®“ä½ è¼•é¬†åœ°å° Google API é€²è¡Œèº«ä»½é©—è­‰ä¸¦å‘é€™äº› API ç™¼é€è«‹æ±‚ï¼Œå¯ä»¥å¤§å¹…ç°¡åŒ–æ‡‰ç”¨ç¨‹å¼çš„é–‹ç™¼æµç¨‹ã€‚

    > å¦‚æœä½ ä½¿ç”¨ Cloud Shell æ“ä½œçš„è©±ï¼Œå°±ä¸éœ€é€™ä¸€æ­¥é©Ÿï¼Œå› ç‚º ADC å·²ç¶“å…§å»ºã€‚

## 2. å»ºç«‹ Python è™›æ“¬ç’°å¢ƒ

åœ¨å‘½ä»¤æç¤ºå­—å…ƒä¸­åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ä¾†å»ºç«‹ä¸€å€‹ Python è™›æ“¬ç’°å¢ƒï¼š

```bash
python -m venv .venv
```

è‹¥ä½¿ç”¨ Visual Studio Code é–‹ç™¼ç’°å¢ƒï¼Œä¹Ÿå¯ä»¥é€é VS Code çš„ GUI ä»‹é¢å»ºç«‹è™›æ“¬ç’°å¢ƒã€‚è©³æƒ…è«‹è¦‹: [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments) æ–‡ä»¶çš„ [Creating environments](https://code.visualstudio.com/docs/python/environments#_creating-environments) å°ç¯€ã€‚

å•Ÿå‹•è™›æ“¬ç’°å¢ƒï¼š

- **Windows ç³»çµ±**

  Command Prompt

  ```bat
  .venv\Scripts\activate
  ```

  PowerShell

  ```ps1
  . .\.venv\Scripts\activate.ps1
  ```

- **macOS/Linux ç³»çµ±**

  ```bash
  source .venv/bin/activate
  ```

## 3. å®‰è£å¿…è¦å¥—ä»¶

[Chirp](https://cloud.google.com/speech-to-text/v2/docs/chirp-model) è¢«æ•´åˆåœ¨ Google Cloud çš„ [Speech-to-Text API v2](https://cloud.google.com/speech-to-text/v2/docs) ä¹‹ä¸­ï¼Œæ‰€ä»¥æˆ‘å€‘éœ€è¦å®‰è£ `google-cloud-speech` å¥—ä»¶ã€‚åœ¨ Python è™›æ“¬ç’°å¢ƒä¸­ï¼Œå¯ä»¥ä½¿ç”¨ `pip` å®‰è£ï¼š

```bash
pip install --upgrade google-cloud-speech
```

> [Speech-to-Text client libraries](https://cloud.google.com/speech-to-text/v2/docs/libraries#client-libraries-install-python)

å»ºç«‹ `requirements.txt` æª”æ¡ˆï¼š

```bash
pip freeze > requirements.txt
```

## 4. æ’°å¯« Chirp ç¨‹å¼ç¢¼

Chirp ä¸»è¦æä¾›å…©ç¨®ç”¨æ³•ï¼š

1. [Synchronous speech recognition](https://cloud.google.com/speech-to-text/v2/docs/sync-recognize)

    é©ç”¨æ–¼**çŸ­éŸ³é »**ç‰‡æ®µ (æœ€å¤š `60` ç§’çš„éŸ³é »)ï¼Œå¯ç«‹å³è¿”å›è½‰éŒ„çµæœã€‚

    åŒæ­¥èªéŸ³è¾¨è­˜å¯ä»¥è½‰éŒ„**æœ¬æ©Ÿä¸Šå‚³çš„ WAV æª”æ¡ˆ**æˆ–æ˜¯å„²å­˜åœ¨ **Cloud Storage** çš„éŸ³è¨Šã€‚

    > æ³¨æ„: æä¾›è¶…é `60s` æˆ– `10MB` çš„éŸ³é »æœƒå°è‡´ API è¿”å›éŒ¯èª¤ï¼Œè©³è¦‹ [quotas and limits](https://cloud.google.com/speech-to-text/v2/quotas) èªªæ˜ã€‚

2. [Batch speech recognition](https://cloud.google.com/speech-to-text/v2/docs/batch-recognize)

    é©ç”¨æ–¼**é•·éŸ³é »**ç‰‡æ®µ (è¶…é `60` ç§’çš„éŸ³é »)ï¼Œä»¥é€ééåŒæ­¥æ–¹å¼é€²è¡Œè½‰éŒ„ï¼Œä½†éåŒæ­¥èªéŸ³è¾¨è­˜çš„ä¸Šé™ ç‚º 480 åˆ†é˜ (å³ 8 å°æ™‚)ã€‚

    æ‰¹æ¬¡èªéŸ³è¾¨è­˜åƒ…èƒ½è½‰éŒ„å„²å­˜åœ¨ **Cloud Storage** çš„éŸ³è¨Šã€‚

ä»¥ä¸‹æˆ‘ç›´æ¥åˆ—å‡ºä¸€æ®µå®Œæ•´çš„ Python åŸå§‹ç¢¼ï¼Œç¤ºç¯„ã€ŒåŒæ­¥èªéŸ³è¾¨è­˜ã€çš„è½‰éŒ„æ–¹æ³•ï¼ŒåŸå§‹ç¢¼æ”¾å…¥ `main.py` æª”æ¡ˆå°±å¯ä»¥åŸ·è¡Œï¼š

```python
import os

from google.api_core.client_options import ClientOptions
from google.cloud.speech_v2 import SpeechClient
from google.cloud.speech_v2.types import cloud_speech

PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT")

def transcribe_chirp_auto_detect_language(
    audio_file: str,
    region: str = "us-central1",
) -> cloud_speech.RecognizeResponse:
    """Transcribe an audio file and auto-detect spoken language using Chirp.
    Please see https://cloud.google.com/speech-to-text/v2/docs/encoding for more
    information on which audio encodings are supported.
    Args:
        audio_file (str): Path to the local audio file to be transcribed.
        region (str): The region for the API endpoint.
    Returns:
        cloud_speech.RecognizeResponse: The response containing the transcription results.
    """
    # Instantiates a client
    client = SpeechClient(
        client_options=ClientOptions(
            api_endpoint=f"{region}-speech.googleapis.com",
        )
    )

    # Reads a file as bytes
    with open(audio_file, "rb") as f:
        audio_content = f.read()

    config = cloud_speech.RecognitionConfig(
        auto_decoding_config=cloud_speech.AutoDetectDecodingConfig(),
        # Set language code to auto to detect language.
        language_codes=["auto"],
        model="chirp",
    )

    request = cloud_speech.RecognizeRequest(
        recognizer=f"projects/{PROJECT_ID}/locations/{region}/recognizers/_",
        config=config,
        content=audio_content,
    )

    # Transcribes the audio into text
    response = client.recognize(request=request)

    for result in response.results:
        print(f"Transcript: {result.alternatives[0].transcript}")
        print(f"Detected Language: {result.language_code}")

    return response

def transcribe_chirp(
    audio_file: str,
    language_code: str = "en-US",
    region: str = "us-central1",
) -> cloud_speech.RecognizeResponse:
    """Transcribes an audio file using the Chirp model of Google Cloud Speech-to-Text API.
    Args:
        audio_file (str): Path to the local audio file to be transcribed.
            Example: "resources/audio.wav"
        language_code (str): The language code to use for transcription.
            Default is "en-US".
        region (str): The region for the API endpoint.
            Default is "us-central1".
    Returns:
        cloud_speech.RecognizeResponse: The response from the Speech-to-Text API containing
        the transcription results.
    """
    # Instantiates a client
    client = SpeechClient(
        client_options=ClientOptions(
            api_endpoint=f"{region}-speech.googleapis.com",
        )
    )

    # Reads a file as bytes
    with open(audio_file, "rb") as f:
        audio_content = f.read()

    config = cloud_speech.RecognitionConfig(
        auto_decoding_config=cloud_speech.AutoDetectDecodingConfig(),
        language_codes=[language_code],
        model="chirp",
    )

    request = cloud_speech.RecognizeRequest(
        recognizer=f"projects/{PROJECT_ID}/locations/{region}/recognizers/_",
        config=config,
        content=audio_content,
    )

    # Transcribes the audio into text
    response = client.recognize(request=request)

    for result in response.results:
        print(f"Transcript: {result.alternatives[0].transcript}")

    return response

def main():
    """
    ç¤ºç¯„å¦‚ä½•å…ˆåµæ¸¬èªè¨€ï¼Œå†æ ¹æ“šåµæ¸¬çµæœé€²è¡Œè½‰éŒ„
    """
    audio_file = "audio_files/é–‹å•Ÿ Google ç€è¦½å™¨.wav"

    print("æ­¥é©Ÿ 1: åµæ¸¬éŸ³è¨Šæª”æ¡ˆçš„èªè¨€...")
    detect_response = transcribe_chirp_auto_detect_language(audio_file)

    # å¾åµæ¸¬çµæœä¸­ç²å–èªè¨€ä»£ç¢¼
    detected_language = None
    if detect_response.results:
        detected_language = detect_response.results[0].language_code
        print(f"åµæ¸¬åˆ°çš„èªè¨€: {detected_language}")
    else:
        # Speech-to-Text V2 supported languages
        # https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages
        print("ç„¡æ³•åµæ¸¬èªè¨€ï¼Œä½¿ç”¨é è¨­èªè¨€ (cmn-Hant-TW)")
        detected_language = "cmn-Hant-TW"

    detected_language = "en-US"
    audio_file = "audio_files/Open Google Chrome.wav"

    print("\næ­¥é©Ÿ 2: ä½¿ç”¨æŒ‡å®šçš„èªè¨€ en-US é€²è¡Œç²¾ç¢ºè½‰éŒ„...")
    transcribe_response = transcribe_chirp(
        audio_file,
        language_code=detected_language
    )

    detected_language = "cmn-Hant-TW"
    audio_file = "audio_files/é–‹å•Ÿ Google ç€è¦½å™¨.wav"

    print("\næ­¥é©Ÿ 3: ä½¿ç”¨æŒ‡å®šçš„èªè¨€ cmn-Hant-TW é€²è¡Œç²¾ç¢ºè½‰éŒ„...")
    transcribe_response = transcribe_chirp(
        audio_file,
        language_code=detected_language
    )

    print("\nè½‰éŒ„å®Œæˆ!")

    return transcribe_response

if __name__ == "__main__":
    main()
```

åŸ·è¡Œ `main.py` ç¨‹å¼ç¢¼ï¼š

```bash
python main.py
```

ä½ æ‡‰è©²æœƒçœ‹åˆ°é¡ä¼¼ä»¥ä¸‹çš„è¼¸å‡ºï¼š

```bash
æ­¥é©Ÿ 1: åµæ¸¬éŸ³è¨Šæª”æ¡ˆçš„èªè¨€...
Transcript:  å¼€ å¯ æµ è§ˆ å™¨
Detected Language: zh-Hans
åµæ¸¬åˆ°çš„èªè¨€: zh-Hans

æ­¥é©Ÿ 2: ä½¿ç”¨æŒ‡å®šçš„èªè¨€ en-US é€²è¡Œç²¾ç¢ºè½‰éŒ„...
Transcript:  open google chrome

æ­¥é©Ÿ 3: ä½¿ç”¨æŒ‡å®šçš„èªè¨€ cmn-Hant-TW é€²è¡Œç²¾ç¢ºè½‰éŒ„...
Transcript:  é–‹å•Ÿæµå™¨

è½‰éŒ„å®Œæˆ!
```

## 5. çµèª

é€™ç¯‡æ–‡ç« æˆ‘å€‘ä»‹ç´¹äº† Google Cloud çš„ Chirp é€šç”¨èªéŸ³æ¨¡å‹ï¼Œä¸¦ç¤ºç¯„äº†å¦‚ä½•ä½¿ç”¨ Python èªè¨€é€²è¡ŒèªéŸ³è½‰æ–‡å­—ã€‚

æˆ‘è‡ªå·±å¯¦æ¸¬çš„çµæœï¼Œç™¼ç¾ã€Œè‹±æ–‡ã€çš„è­˜åˆ¥ç‡éå¸¸é«˜ï¼Œè€Œã€Œä¸­æ–‡ã€çš„è­˜åˆ¥ç‡å‰‡ç›¸å°è¼ƒä½ï¼Œä¸”å«ç„¡æ³•å€åˆ†ä¸åŒåœ°å€çš„å£éŸ³ã€‚ä½ æ‡‰è©²å¯ä»¥å¾çµæœç™¼ç¾ï¼Œè©²æ¨¡å‹é›–ç„¶å®£ç¨± Universal speech model (USM) (é€šç”¨èªéŸ³æ¨¡å‹) å¯ä»¥è™•ç†å¤šç¨®èªè¨€ï¼Œä½†åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œé‚„æ˜¯å°æ–¼å°ç£é€™é‚Šçš„å£éŸ³ï¼Œè¾¨è­˜ç‡ä¾ç„¶ä¸é«˜ï¼Œæœƒè‡ªå‹•è¾¨è­˜ç‚ºç°¡é«”ä¸­æ–‡(`zh-Hans`)ã€‚å¦å¤–ä¸€å€‹å•é¡Œæ˜¯ï¼Œå°ç£äººè¬›è©±å¾ˆå–œæ­¡ç”¨æ™¶æ™¶é«”èªªè©±ï¼Œä¹Ÿå°±æ˜¯å¾ˆå–œæ­¡å¤¾é›œè‘—ä¸­ã€è‹±æ–‡æ··è‘—èªªï¼Œè€Œé€™ç¨®èªéŸ³åœ¨ Chirp çš„è¾¨è­˜ç‡ä¾ç„¶éå¸¸ä½ï¼Œå¤§éƒ¨åˆ†æ™‚å€™æœƒç›´æ¥æ¿¾æ‰è‹±æ–‡çš„éƒ¨åˆ†ã€‚

ä¸éï¼ŒGoogle å° USM é‡å¿ƒå¾ˆå¤§ï¼Œç›®å‰ä»–å€‘å·²ç¶“ç”¨äº† 1,200 è¬å°æ™‚çš„èªéŸ³æª”é€²è¡Œè‡ªç›£ç£è¨“ç·´ï¼Œåœ¨ä¸€ç™¾å¤šç¨®èªè¨€å¾®èª¿äº† 280 å„„å€‹å¥å­ï¼Œè¨“ç·´å‡ºäº†ä¸€å€‹ `2B` åƒæ•¸çš„æ¨¡å‹ã€‚å…¶å¯¦ `2B` å…¶å¯¦è »å°çš„ï¼Œè¦è™•ç†é€™éº¼å¤šçš„èªè¨€ï¼Œæˆ‘è¦ºå¾—é‚„æ˜¯ç›¸ç•¶å›°é›£ã€‚é€™å€‹ Chirp æ¨¡å‹é›–ç„¶å¯ä»¥è™•ç†å¤šç¨®èªè¨€çš„èªéŸ³ï¼Œä½†åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œé‚„æ˜¯æœ‰å¾ˆå¤šå•é¡Œéœ€è¦è§£æ±ºï¼Œå°¤å…¶æ˜¯å¤šèªè¨€çš„èªéŸ³è¾¨è­˜éƒ¨åˆ†ï¼ŒæœŸå¾…æœªä¾† Google çš„èªéŸ³æŠ€è¡“å¯ä»¥è§£æ±ºé€™äº›å•é¡Œï¼Œå¸Œæœ›æœ‰ä¸€å¤©å¯ä»¥ä¸ç”¨å†æ‰“å­—äº†ï¼ğŸ˜„

### ç›¸é—œé€£çµ

- [Package google.cloud.speech.v2 | Cloud Speech-to-Text V2 documentation | Google Cloud](https://cloud.google.com/speech-to-text/v2/docs/reference/rpc/google.cloud.speech.v2#google.cloud.speech.v2.Speech.BatchRecognize)
- [Speech-to-Text API å®šåƒ¹ | Google Cloud](https://cloud.google.com/speech-to-text/pricing?hl=zh_tw)
- [Perfect voice applications with Chirp and speech fine tuning - YouTube](https://www.youtube.com/watch?v=xT348FrrFZ0)
